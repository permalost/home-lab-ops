apiVersion: v1
kind: ConfigMap
metadata:
  name: litellm-config-file
data:
  config.yaml: |
    model_list: 
      - model_name: gpt-3.5-turbo
        litellm_params:
          model: azure/gpt-turbo-small-ca
          api_base: https://my-endpoint-canada-berri992.openai.azure.com/
          api_key: os.environ/CA_AZURE_OPENAI_API_KEY
---
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: litellm-secrets
data:
  CA_AZURE_OPENAI_API_KEY: bWVvd19pbV9hX2NhdA== # your api key in base64
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: litellm
  labels:
    app: litellm
spec:
  selector:
    matchLabels:
      app: litellm
  template:
    metadata:
      labels:
        app: litellm
    spec:
      containers:
        - name: litellm
          image: ghcr.io/berriai/litellm:main-latest # it is recommended to fix a version generally
          ports:
            - containerPort: 4000
          volumeMounts:
            - name: config-volume
              mountPath: /app/proxy_server_config.yaml
              subPath: config.yaml
          envFrom:
            - secretRef:
                name: litellm-secrets
      volumes:
        - name: config-volume
          configMap:
            name: litellm-config-file
